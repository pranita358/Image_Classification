{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/bajajvbh/Desktop/Vaibhav/Datasets/digitsnpixels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploratory Data Analysis\n",
    "print(f\"There are {A.shape[0]} rows and {A.shape[1]} columns\")\n",
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features X (independent variables) and target/label y (dependent variable)\n",
    "X=A.to_numpy()[:,1:]\n",
    "y=A.to_numpy()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value range of X\n",
    "X.min(),X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the array shape of a single data (image)\n",
    "X[0].shape\n",
    "np.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the image data into 2D array, and plot the image\n",
    "plt.imshow(X[8].reshape(28,28),cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count and show the number of data for each label/target y\n",
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Data Preprocessing\n",
    "\n",
    "# normalizing features (pixels)\n",
    "X = X / 255.0\n",
    "\n",
    "# one-hot-encoding target (digit 0-9)\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "#This function returns a matrix of binary values (either ‘1’ or ‘0’).\n",
    "#It has number of rows equal to the length of the input vector and number of columns equal to the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xval,ytrain,yval=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data to fit Keras's input configuration (rank 4 tensor: (rows, pixel, pixel, channel))\n",
    "\n",
    "xtrain=xtrain.reshape(xtrain.shape[0],28,28,1)\n",
    "xval=xval.reshape(xval.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Keras Model\n",
    "model=tf.keras.Sequential()\n",
    "\n",
    "# add first convolution layer\n",
    "model.add(tf.keras.layers.Convolution2D(filters=10,kernel_size=(3,3),activation=\"relu\",input_shape=(28,28,1)))\n",
    "\n",
    "#How much u wish to read and recognize for maxpooling\n",
    "# add first pooling layer\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#add regularization\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "# add second convolution layer\n",
    "model.add(tf.keras.layers.Convolution2D(filters=10,kernel_size=(3,3),activation=\"relu\",input_shape=(28,28,1)))\n",
    "\n",
    "# add second pooling layer\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#add regularization\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "# flatten the array (from 2D to 1D)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#add first fully connected layer\n",
    "model.add(tf.keras.layers.Dense(units=30,activation=\"relu\"))\n",
    "\n",
    "#add second fully connected layer\n",
    "model.add(tf.keras.layers.Dense(units=20,activation=\"relu\"))\n",
    "\n",
    "#add output layer (0-9 classes)\n",
    "model.add(tf.keras.layers.Dense(units=10,activation=\"softmax\"))\n",
    "\n",
    "#compile model\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "# show the network architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "# define early stopping\n",
    "callback=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=3)\n",
    "\n",
    "# fit the model and save the information in history\n",
    "history=model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(xval,yval),\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18,6))\n",
    "ax[0].plot(history.history['loss'], label='train')\n",
    "ax[0].plot(history.history['val_loss'], label='valid')\n",
    "ax[1].plot(history.history['accuracy'], label='train')\n",
    "ax[1].plot(history.history['val_accuracy'], label='valid')\n",
    "ax[0].set_title('Loss')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[0].legend(); ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation on Validation Data\n",
    "\n",
    "results=model.evaluate(xval,yval,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"val loss: {results[0]} and val acc: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities\n",
    "probabilities=model.predict(xval)\n",
    "\n",
    "# get prediction\n",
    "ypred=np.argmax(probabilities,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
